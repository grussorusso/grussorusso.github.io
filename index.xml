<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Home on Gabriele Russo Russo</title><link>https://grussorusso.github.io/</link><description>Recent content in Home on Gabriele Russo Russo</description><generator>Hugo</generator><language>en-us</language><atom:link href="https://grussorusso.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>A framework for offloading and migration of serverless functions in the Edge–Cloud Continuum</title><link>https://grussorusso.github.io/publications/pmc24/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/pmc24/</guid><description>&lt;p>Function-as-a-Service (FaaS) has emerged as an evolution of traditional Cloud service models, allowing users to define and execute pieces of codes (i.e., functions) in a serverless manner, with the provider taking care of most operational issues. With the unending growth of resource availability in the Edge-to-Cloud Continuum, there is increasing interest in adopting FaaS near the Edge as well, to better support geo-distributed and pervasive applications. However, as the existing FaaS frameworks have mostly been designed with Cloud in mind, new architectures are necessary to cope with the additional challenges of the Continuum, such as higher heterogeneity, network latencies, limited computing capacity.&lt;/p></description></item><item><title>A Multi-level Elasticity Framework for Distributed Data Stream Processing</title><link>https://grussorusso.github.io/publications/autodasp18/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/autodasp18/</guid><description>&lt;p>Data Stream Processing (DSP) applications should be capable to efficiently process high-velocity continuous data streams by elastically scaling the parallelism degree of their operators so to deal with high variability in the workload. Moreover, to efficiently use computing resources, modern DSP frameworks should seamlessly support infrastructure elasticity, which allows to exploit resources available on-demand in geo-distributed Cloud and Fog systems. In this paper we propose E2DF, a framework to autonomously control the multi-level elasticity of DSP applications and the underlying computing infrastructure. E2DF revolves around a hierarchical approach, with two control layers that work at different granularity and time scale. At the lower level, fully decentralized Operator and Region managers control the reconfiguration of distributed DSP operators and resources. At the higher level, centralized managers oversee the overall application and infrastructure adaptation. We have integrated the proposed solution into Apache Storm, relying on a previous extension we developed, and conducted an experimental evaluation. It shows that, even with simple control policies, E2DF can improve resource utilization without application performance degradation.&lt;/p></description></item><item><title>AI-driven Performance Management in Data-Intensive Applications</title><link>https://grussorusso.github.io/publications/bookai2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/bookai2021/</guid><description/></item><item><title>Auto-scaling in Data Stream Processing: a Model Based Reinforcement Learning Approach</title><link>https://grussorusso.github.io/publications/infq17/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/infq17/</guid><description>&lt;p>By exploiting on-the-fly computation, Data Stream Processing (DSP) applications can process huge volumes of data in a near real-time fashion. Adapting the application parallelism at run-time is critical in order to guarantee a proper level of QoS in face of varying workloads. In this paper, we consider Reinforcement Learning based techniques in order to self-configure the number of parallel instances for a single DSP operator. Specifically, we propose two model-based approaches and compare them to the baseline Q-learning algorithm. Our numerical investigations show that the proposed solutions provide better performance and faster convergence than the baseline.&lt;/p></description></item><item><title>Compute continuum: What lies ahead?</title><link>https://grussorusso.github.io/publications/wscc23/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/wscc23/</guid><description>&lt;p>Modern computing environments are evolving towards the compute continuum paradigm, which promises to manage the heterogeneity and dynamism of geographically spread computing resources, supporting the execution of distributed and pervasive applications. As a complete understanding of all the implications and challenges posed by this new paradigm is still far, we give an overview of the key features and concepts of the compute continuum and discuss the most relevant research opportunities we envision in the field.&lt;/p></description></item><item><title>Decentralized self-adaptation for elastic Data Stream Processing</title><link>https://grussorusso.github.io/publications/fgcs18/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/fgcs18/</guid><description>&lt;p>Data Stream Processing (DSP) applications are widely used to develop new
pervasive services, which require to seamlessly process huge amounts of data in
a near real-time fashion. To keep up with the high volume of daily produced
data, these applications need to dynamically scale their execution on multiple
computing nodes, so to process the incoming data flow in parallel. In this
paper, we present a hierarchical distributed architecture for the autonomous
control of elastic DSP applications. It consists of a two-layered hierarchical
solution, where a centralized per-application component coordinates the run-time
adaptation of subordinated distributed components, which, in turn, locally
control the adaptation of single DSP operators. Thanks to its features, the
proposed solution can efficiently run in large-scale Fog computing environments.
Exploiting this framework, we design several distributed self-adaptation
policies, including a popular threshold-based approach and two reinforcement
learning solutions. We integrate the hierarchical architecture and the devised
self-adaptation policies in Apache Storm, a popular open-source DSP framework.
Relying on the DEBS 2015 Grand Challenge as a benchmark application, we show the
benefits of the presented self-adaptation policies, and discuss the strengths of
reinforcement learning based approaches, which autonomously learn from
experience how to optimize the application performance.&lt;/p></description></item><item><title>Elastic Pulsar Functions for Distributed Stream Processing</title><link>https://grussorusso.github.io/publications/autodasp21/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/autodasp21/</guid><description>&lt;p>An increasing number of data-driven applications rely on the ability of
processing data flows in a timely manner, exploiting for this purpose Data
Stream Processing~(DSP) systems. Elasticity is an essential feature for DSP
systems, as workload variability calls for automatic scaling of the application
processing capacity, to avoid both overload and resource wastage. In this work,
we implement auto-scaling in Pulsar Functions, a function-based streaming
framework built on top of Apache Pulsar. The latter is is a distributed
publish-subscribe messaging platform that natively supports serverless
functions. Considering various state-of-the-art policies, we show that the
proposed solution is able to scale application parallelism with minimal
overhead.&lt;/p></description></item><item><title>FIGARO: reinForcement learnInG mAnagement acRoss the computing cOntinuum</title><link>https://grussorusso.github.io/publications/figaro23/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/figaro23/</guid><description>&lt;p>The widespread adoption of Artificial Intelligence applications to analyze data generated by Internet of Things sensors
leads to the development of the edge computing paradigm.
Deploying applications at the periphery of the network effectively addresses cost and latency concerns associated with
cloud computing. However, it generates a highly distributed
environment with heterogeneous devices, opening the challenges of how to select resources and place application com-
ponents. Starting from a state-of-the-art design-time tool, we
present in this paper a novel framework based on Reinforcement Learning, named FIGARO (reinForcement learnInG
mAnagement acRoss the computing cOntinuum). It handles
the runtime adaptation of a computing continuum environment, dealing with the variability of the incoming load and
service times. To reduce the training time, we exploit the
design-time knowledge, achieving a significant reduction in
the violations of the response time constraint.&lt;/p></description></item><item><title>Hierarchical Auto-Scaling Policies for Data Stream Processing on Heterogeneous Resources</title><link>https://grussorusso.github.io/publications/taas23/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/taas23/</guid><description>&lt;p>Data Stream Processing (DSP) applications analyze data flows in near real-time by means of operators, which process and transform incoming data. Operators handle high data rates running parallel replicas across multiple processors and hosts. To guarantee consistent performance without wasting resources in face of variable workloads, auto-scaling techniques have been studied to adapt operator parallelism at run-time. However, most the effort has been spent under the assumption of homogeneous computing infrastructures, neglecting the complexity of modern environments.&lt;/p></description></item><item><title>MEAD: Model-based Vertical Auto-Scaling for Data Stream Processing</title><link>https://grussorusso.github.io/publications/ccgrid2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/ccgrid2021/</guid><description>&lt;p>The unpredictable variability of Data Stream Processing (DSP) application workloads calls for advanced mechanisms and policies for elastically scaling the processing capacity
of DSP operators. Whilst many different approaches have been
used to devise policies, most of the solutions have focused on data
arrival rate and operator resource utilization as key metrics for
auto-scaling. We here show that, under burstiness in the data
flows, overly simple characterizations of the input stream can
yet lead to very inaccurate performance estimations that affect
such policies, resulting in sub-optimal resource allocation.
We then present MEAD, a vertical auto-scaling solution
that relies on online state-based representation of burstiness
to drive resource allocation. We use in particular Markovian
Arrival Processes (MAPs), which are composable with analytical
queueing models, allowing us to efficiently predict performance
at run-time under burstiness. We integrate MEAD in Apache
Flink, and evaluate its benefits over simpler yet popular auto-scaling solutions, using both synthetic and real-world workloads.
Differently from existing approaches, MEAD satisfies response
time requirements under burstiness, while saving up to 50% CPU
resources with respect to a static allocation.&lt;/p></description></item><item><title>Model-based Auto-Scaling of Distributed Data Stream Processing Applications</title><link>https://grussorusso.github.io/publications/middleware2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/middleware2020/</guid><description>&lt;p>Data Stream Processing (DSP) enables near real-time analysis of fast data streams, produced, e.g., by Internet-of-Things devices. Distributed DSP systems exploit distributed computing infrastructures, possibly spanning both Cloud and Fog/Edge platforms, to scale their execution and cope with high-volume streams. To avoid resource under-provisioning or wastage in face of highly variable workloads, DSP applications should elastically acquire and release resources as needed. In this doctoral work we investigate mechanisms and policies to auto-scale DSP applications. Differently from most previous works, we consider resource heterogeneity and model uncertainty as primary challenges. Moreover, we devise a hierarchical control scheme to avoid the scalability issues that may affect centralized solutions.&lt;/p></description></item><item><title>Multi-Level Elasticity for Wide-Area Data Streaming Systems: A Reinforcement Learning Approach</title><link>https://grussorusso.github.io/publications/mdpi18/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/mdpi18/</guid><description>&lt;p>The capability of efficiently processing the data streams emitted by nowadays ubiquitous sensing devices enables the development of new intelligent services. Data Stream Processing (DSP) applications allow for processing huge volumes of data in near real-time. To keep up with the high volume and velocity of data, these applications can elastically scale their execution on multiple computing resources to process the incoming data flow in parallel. Being that data sources and consumers are usually located at the network edges, nowadays the presence of geo-distributed computing resources represents an attractive environment for DSP. However, controlling the applications and the processing infrastructure in such wide-area environments represents a significant challenge. In this paper, we present a hierarchical solution for the autonomous control of elastic DSP applications and infrastructures. It consists of a two-layered hierarchical solution, where centralized components coordinate subordinated distributed managers, which, in turn, locally control the elastic adaptation of the application components and deployment regions. Exploiting this framework, we design several self-adaptation policies, including reinforcement learning based solutions. We show the benefits of the presented self-adaptation policies with respect to static provisioning solutions, and discuss the strengths of reinforcement learning based approaches, which learn from experience how to optimize the application performance and resource allocation.&lt;/p></description></item><item><title>Optimal operator deployment and replication for elastic distributed data stream processing</title><link>https://grussorusso.github.io/publications/ccpe18/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/ccpe18/</guid><description>&lt;p>Processing data in a timely manner, data stream processing (DSP) applications are receiving an increasing interest for building new pervasive services. Due to the unpredictability of data sources, these applications often operate in dynamic environments; therefore, they require the ability to elastically scale in response to workload variations. In this paper, we deal with a key problem for the effective runtime management of a DSP application in geo‐distributed environments: We investigate the placement and replication decisions while considering the application and resource heterogeneity and the migration overhead, so to select the optimal adaptation strategy that can minimize migration costs while satisfying the application quality of service (QoS) requirements. We present elastic DSP replication and placement (EDRP), a unified framework for the QoS‐aware initial deployment and runtime elasticity management of DSP applications. In EDRP, the deployment and runtime decisions are driven by the solution of a suitable integer linear programming problem, whose objective function captures the relative importance between QoS goals and reconfiguration costs. We also present the implementation of EDRP and the related mechanisms on Apache Storm. We conduct a thorough experimental evaluation, both numerical and protopublication_type‐based, that shows the benefits achieved by EDRP on the application performance.&lt;/p></description></item><item><title>QoS-aware offloading policies for serverless functions in the Cloud-to-Edge continuum</title><link>https://grussorusso.github.io/publications/fgcs24/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/fgcs24/</guid><description>&lt;p>Function-as-a-Service (FaaS) paradigm is increasingly attractive to bring the benefits of serverless computing to the edge of the network, besides traditional Cloud data centers. However, FaaS adoption in the emerging Cloud-to-Edge Continuum is challenging, mostly due to geographical distribution and heterogeneous resource availability. This emerging landscape calls for effective strategies to trade off low latency at the edge of the network with Cloud resource richness, taking into account the needs of different functions and users.&lt;/p></description></item><item><title>Real-Time Analysis of Market Data Leveraging Apache Flink</title><link>https://grussorusso.github.io/publications/debs22/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/debs22/</guid><description>&lt;p>In this paper, we present a solution to the DEBS 2022 Grand Challenge (GC). According to the GC requirements, the proposed software continuously observes notifications about financial instruments being traded, aiming to timely detect breakout patterns. Our solution leverages Apache Flink, an open-source, scalable stream processing platform, which allows us to process incoming data streams with low latency and exploit the parallelism offered by the underlying computing infrastructure.&lt;/p></description></item><item><title>Reinforcement learning based policies for elastic stream processing on heterogeneous resources</title><link>https://grussorusso.github.io/publications/debs19/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/debs19/</guid><description>&lt;p>Data Stream Processing (DSP) has emerged as a key enabler to develop pervasive services that require to process data in a near real-time fashion. DSP applications keep up with the high volume of produced data by scaling their execution on multiple computing nodes, so as to process the incoming data flow in parallel. Workloads variability requires to elastically adapt the application parallelism at run-time in order to avoid over-provisioning. Elasticity policies for DSP have been widely investigated, but mostly under the simplifying assumption of homogeneous infrastructures. The resulting solutions do not capture the richness and inherent complexity of modern infrastructures, where heterogeneous computing resources are available on-demand. In this paper, we formulate the problem of controlling elasticity on heterogeneous resources as a Markov Decision Process (MDP). The resulting MDP is not easily solved by traditional techniques due to state space explosion, and thus we show how linear Function Approximation and Tile Coding can be used to efficiently compute elasticity policies at run-time. In order to deal with parameters uncertainty, we integrate the proposed approach with Reinforcement Learning algorithms. Our numerical evaluation shows the efficacy of the presented solutions compared to standard methods in terms of accuracy and convergence speed.&lt;/p></description></item><item><title>Run-Time Adaptation of Data Stream Processing Systems: The State of the Art</title><link>https://grussorusso.github.io/publications/csur2022/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/csur2022/</guid><description>&lt;p>Data Stream Processing (DSP) has emerged over the years as the reference paradigm for the analysis of
continuous and fast information flows, which have often to be processed with low-latency requirements to
extract insights and knowledge from raw data. Dealing with unbounded data flows, DSP applications are
typically long-running and, thus, likely experience varying workloads and working conditions over time. To
keep a consistent service level in face of such variability, a lot of effort has been spent studying strategies for
run-time adaptation of DSP systems and applications. In this survey, we review the most relevant approaches
from the literature, presenting a taxonomy to characterize the state of the art along several key dimensions.
Our analysis allows us to identify current research trends as well as open challenges that will motivate further
investigations in this field.&lt;/p></description></item><item><title>Self-Adaptive Data Stream Processing in Geo-Distributed Computing Environments</title><link>https://grussorusso.github.io/publications/debs19doctsymp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/debs19doctsymp/</guid><description>&lt;p>An ever increasing number of services requires real-time analysis of collected data streams. Emerging Fog/Edge computing platforms are appealing for such latency-sensitive applications, encouraging the deployment of Data Stream Processing (DSP) systems in geo-distributed environments. However, the highly dynamic nature of these infrastructures poses challenges on how to satisfy the Quality of Service requirements of both the application and the infrastructure providers.&lt;/p>
&lt;p>In this doctoral work we investigate how DSP systems can face the dynamicity of workloads and computing environments by self-adapting their deployment and behavior at run-time. Targeting geo-distributed infrastructures, we specifically search for decentralized solutions, and propose a framework for organizing adaptation using a hierarchical control approach. Focusing on application elasticity, we equip the framework with decentralized policies based on reinforcement learning. We extend our solution to consider multi-level elasticity, and heterogeneous computing resources. In the ongoing research work, we aim to face the challenges associated with mobility of users and computing resources, exploring complementary adaptation mechanisms.&lt;/p></description></item><item><title>Serverledge: Decentralized Function-as-a-Service for the Edge-Cloud Continuum</title><link>https://grussorusso.github.io/publications/percom2023/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/percom2023/</guid><description>&lt;p>As the Function-as-a-Service (FaaS) paradigm enjoys growing popularity within Cloud-based systems, there is increasing interest in moving serverless functions towards the Edge, to better support geo-distributed and pervasive applications. However, enjoying both the reduced latency of Edge and the scalability of FaaS is not straightforward, calling for new architectures and implementations to cope with Edge challenges (e.g., nodes with limited computational capacity). While first solutions have been proposed for Edge-based FaaS, including light function sandboxing techniques, we lack a platform with the ability to span both Edge and Cloud and adaptively exploit both. In this paper, we present Serverledge, a FaaS platform designed for the Edge-to-Cloud continuum. Serverledge adopts a decentralized architecture, where function invocation requests can be fully served within Edge nodes in most the cases. To cope with load peaks, Serverledge also supports vertical (i.e., from Edge to Cloud) and horizontal (i.e., among Edge nodes) computation offloading. Our evaluation shows that Serverledge outperforms Apache OpenWhisk in an Edge-like scenario and has competitive performance with state-of-the-art frameworks optimized for the Edge, with the advantage of built-in support for vertical and horizontal offloading.&lt;/p></description></item><item><title>Serverless functions in the cloud-edge continuum: Challenges and opportunities</title><link>https://grussorusso.github.io/publications/pdp2023/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/pdp2023/</guid><description>&lt;p>The Function-as-a-Service (FaaS) paradigm is increasingly adopted for the development of Cloud-native applications, which especially benefit from the seamless scalability
and attractive pricing models of serverless deployments. With
the continuous emergence of latency-sensitive applications and
services, including Internet-of-Things and augmented reality, it
is now natural to wonder whether and how the FaaS paradigm
can be efficiently exploited in the Cloud-Edge Continuum, where
serverless functions may benefit from reduced network delay
between their invoking users and the FaaS platform.&lt;/p></description></item><item><title>Software</title><link>https://grussorusso.github.io/software/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/software/</guid><description>&lt;h3 id="serverledge">Serverledge&lt;/h3>
&lt;p>A Function-as-a-Service framework designed for Edge-Cloud environments,
&lt;a href="https://doi.org/10.1109/PERCOM56429.2023.10099372">presented at &lt;em>IEEE PerCom
&amp;lsquo;23&lt;/em>&lt;/a>.
Serverledge relies on a decentralized architecture, with no centralized
gateways for function invocations, and supports horizontal and vertical
function execution offloading.
Written in Go.&lt;/p>
&lt;p>&lt;a href="https://github.com/grussorusso/serverledge">GitHub&lt;/a>&lt;/p></description></item><item><title>Teaching</title><link>https://grussorusso.github.io/teaching/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/teaching/</guid><description>&lt;p>In the A.Y. 2024/25 I teach the following courses for the MSc in Computer
Science (in Italian):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="http://www.ce.uniroma2.it/courses/ml2425/">&lt;em>Machine Learning&lt;/em>&lt;/a> (6 ECTS taught by me; 3 ECTS taught by Francesco Lo
Presti)&lt;/li>
&lt;li>&lt;a href="http://www.ce.uniroma2.it/courses/sdcc2425/">&lt;em>Distributed Systems and Cloud
Computing&lt;/em>&lt;/a> (1 ECTS taught by me; 8 ECTS taught by Valeria Cardellini)&lt;/li>
&lt;/ul>
&lt;p>In March/April 2024, I also hold a 10-hour doctoral course on &lt;em>Reinforcement
Learning for Run-time Performance Management&lt;/em>. &lt;a href="https://grussorusso.github.io/slides/RL-Roma2.pdf">Slides
(partial)&lt;/a>&lt;/p>
&lt;p>Check my &lt;a href="https://grussorusso.github.io/cv.pdf">CV&lt;/a> for
more information about courses I taught in the past and other teaching
activities I am involved in.&lt;/p></description></item><item><title>Towards a Security-aware Deployment of Data Streaming Applications in Fog Computing</title><link>https://grussorusso.github.io/publications/booksecurity2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/booksecurity2020/</guid><description>&lt;p>Emerging fog and edge computing environments enable the analysis of Big Data collected from devices (e.g., IoT sensors) with reduced latency compared to cloud-based solutions. In particular, many applications deal with continuous data flows in latency-sensitive domains (e.g., healthcare monitoring), where Data Stream Processing (DSP) systems represent a popular solution. However, the highly heterogeneous nature of fog/edge platforms poses several challenges for efficiently deploying DSP applications, including security and privacy issues. As data streams flow through public networks and are possibly processed within multi-tenant computing platforms, new metrics must be considered for deployment, accounting for security and privacy related concerns, besides traditionally adopted performance and cost aspects. In this chapter, we present the most relevant existing solutions for deploying DSP applications in fog/edge environments, discussing - in particular - how they address security and privacy concerns. Then, we present Security-aware DSP Placement (SDP), a formulation of the optimal deployment problem for DSP applications in fog/edge environments. Specifically, we introduce security-related application requirements in addition to non-functional ones, and show how the resolution of SDP allows us to trade-off cost and performance with privacy and data integrity objectives.&lt;/p></description></item><item><title>Towards Decentralized Auto-Scaling Policies for Data Stream Processing Applications</title><link>https://grussorusso.github.io/publications/zeus18/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/zeus18/</guid><description>&lt;p>Data Stream Processing applications can process large data volumes in near
real-time. In order to face varying workloads in a scalable and cost-effective
manner, it is critical to adjust the application parallelism at run-time. We
formulate the elasticity problem as a Markov Decision Process (MDP). As the MDP
resolution requires full knowledge of the system dynamics, which is rarely
available, we rely on model based Reinforcement Learning to improve the scaling
policy at run-time. We show promising results even for a decentralized approach,
compared tothe optimal MDP solution.&lt;/p></description></item><item><title>Towards hierarchical autonomous control for elastic data stream processing in the fog</title><link>https://grussorusso.github.io/publications/autodasp17/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/autodasp17/</guid><description>&lt;p>In the Big Data era, Data Stream Processing (DSP) applications should be capable
to seamlessly process huge amount of data. Hence, they need to dynamically scale
their execution on multiple computing nodes so to adjust to unpredictable data
source rate. In this paper, we present a hierarchical and distributed
architecture for the autonomous control of elastic DSP applications. It revolves
around a two layered approach. At the lower level, distributed components issue
requests for adapting the deployment of DSP operations as to adjust to changing
workload conditions. At the higher level, a per-application centralized
component works on a broader time scale; it oversees the application behavior
and grants reconfigurations to control the application performance while
limiting the negative effect of their enactment, i.e., application downtime. We
have implemented the proposed solution in our distributed Storm protopublication_type and
evaluated its behavior adopting simple policies. The experimental results are
promising and show that, even with simple policies, it is possible to limit the
number of reconfigurations while at the same time guaranteeing an adequate level
of application performance.&lt;/p></description></item><item><title>Towards QoS-Aware Function Composition Scheduling in Apache OpenWhisk</title><link>https://grussorusso.github.io/publications/starless2022/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/starless2022/</guid><description>&lt;p>Function-as-a-Service (FaaS) is increasingly popular
thanks to the benefits provided to application developers and operators. Besides commercial Cloud-based offerings, open-source
solutions have emerged enabling FaaS deployment on private
infrastructures and possibly at the edge of the network. When
moving from the Cloud to Fog/Edge environments, optimizing
resource allocation for function execution becomes a critical
challenge. Unfortunately, existing FaaS platforms have little or no
support for fine-grained scheduling and resource allocation, nor
allow users to enforce Quality-of-Service (QoS) requirements. We
take a first step towards the development of a QoS-aware FaaS
platform. We design and implement new mechanisms to support
differentiated classes of services within Apache OpenWhisk, a
popular open-source FaaS framework. Our experiments show
that our protopublication_type efficiently supports state-of-the-art scheduling
policies and provides throughput improvements when dealing
with function compositions under high load scenarios.&lt;/p></description></item><item><title>Wasimoff: Distributed Computation Offloading Using WebAssembly in the Browser</title><link>https://grussorusso.github.io/publications/starless24/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://grussorusso.github.io/publications/starless24/</guid><description>&lt;p>Recently, there is a growing trend where end-users personally engage in computationally-intensive applications, particularly in domains such as AI, AR/VR, and simulation. Consequently, there arises an increasing demand to enhance the capabilities of local devices by offloading computational work to remote resources, which can also be provided by end users. To address the requirements of modern peer-to-peer (P2P) offloading architectures, we have developed Wasimoff—an innovative browser-based framework designed for dynamic volunteer computing. Leveraging WebAssembly, applications can securely run in an isolated browser environment. Device owners can effortlessly share their available CPU cycles and participate in the collaborative network by accessing a designated URL in their browser. To assess Wasimoff’s performance, we conducted a real-world evaluation with devices located in both Germany and the USA. The results affirm Wasimoff’s ability to scale linearly as the system’s entities increase. Moreover, Wasimoff consistently maintains execution speed even under congested system conditions.&lt;/p></description></item></channel></rss>