<!doctype html><html lang><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Auto-scaling in Data Stream Processing: a Model Based Reinforcement Learning Approach</title><meta name=description content><meta name=author content="Gabriele Russo Russo"><meta name=google-site-verification content="bPwo8jbhRQyTnf8PZdjYiBqNZ109q7xM6askN5vfJic"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css integrity=sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2 crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin=anonymous><link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://grussorusso.github.io/sass/researcher.min.css></head><body><div class="container mt-5"><nav class="navbar navbar-expand-sm flex-column flex-sm-row text-nowrap p-0"><a class="navbar-brand mx-0 mr-sm-auto" href=https://grussorusso.github.io/ title="Gabriele Russo Russo">Gabriele Russo Russo</a><div class="navbar-nav flex-row flex-wrap justify-content-center"><a class="nav-item nav-link" href=https://grussorusso.github.io/publications title=Publications>Publications</a>
<span class="nav-item navbar-text mx-1 nav-separator">/</span>
<a class="nav-item nav-link" href=https://grussorusso.github.io/service title=Service>Service</a>
<span class="nav-item navbar-text mx-1 nav-separator">/</span>
<a class="nav-item nav-link" href=https://grussorusso.github.io/cv.pdf title=CV>CV</a></div></nav></div><hr><div id=content><div class=container><a href=https://grussorusso.github.io/publications#auto-scaling-in-data-stream-processing-a-model-based-reinforcement-learning-approach>back</a><h2>Auto-scaling in Data Stream Processing: a Model Based Reinforcement Learning Approach</h2><p>V. Cardellini, F. Lo Presti, M. Nardelli, G. Russo Russo</p><p><a style=color:red href=http://www.ce.uniroma2.it/publications/infq2017.pdf>[pdf]</i></a>
<a href=https://doi.org/10.1007/978-3-319-91632-3_8>[doi]</i></i></a></p><p>By exploiting on-the-fly computation, Data Stream Processing (DSP) applications can process huge volumes of data in a near real-time fashion. Adapting the application parallelism at run-time is critical in order to guarantee a proper level of QoS in face of varying workloads. In this paper, we consider Reinforcement Learning based techniques in order to self-configure the number of parallel instances for a single DSP operator. Specifically, we propose two model-based approaches and compare them to the baseline Q-learning algorithm. Our numerical investigations show that the proposed solutions provide better performance and faster convergence than the baseline.</p></div></div><div id=footer class=mb-5><hr><div class="container text-center"><a href=https://github.com/grussorusso class="fab fa-github fa-1x" title=GitHub></a></div><div class="container text-center"><a href=https://grussorusso.github.io/ title><small></small></a></div></div></body></html>