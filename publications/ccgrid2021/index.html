<!doctype html><html lang><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>MEAD: Model-based Vertical Auto-Scaling for Data Stream Processing | Gabriele Russo Russo</title><meta name=description content><meta name=author content="Gabriele Russo Russo"><meta name=google-site-verification content="bPwo8jbhRQyTnf8PZdjYiBqNZ109q7xM6askN5vfJic"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css integrity=sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2 crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin=anonymous><link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css><link rel=stylesheet href=https://grussorusso.github.io/sass/researcher.min.css></head><body><nav class="navbar navbar-expand-md navbar-light" style=background-color:#fff;padding:2px><div class="container mt-3"><a class=custom-brand href=https://grussorusso.github.io/>Gabriele Russo Russo</a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarTogglerDemo02 aria-controls=navbarTogglerDemo02 aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarTogglerDemo02><ul class="navbar-nav ml-auto mt-2 mt-md-0"><li class=nav-item><a class=custom-nav-link href=https://grussorusso.github.io/ title=Home>Home</a></li><li class=nav-item><a class=custom-nav-link href=https://grussorusso.github.io/cv.pdf title=CV>CV</a></li><li class=nav-item><a class=custom-nav-link href=https://grussorusso.github.io/publications title=Publications>Publications</a></li><li class=nav-item><a class=custom-nav-link href=https://grussorusso.github.io/software title=Software>Software</a></li><li class=nav-item><a class=custom-nav-link href=https://grussorusso.github.io/teaching title=Teaching>Teaching</a></li></ul></div></div></nav><hr style=margin-bottom:1.1em;margin-top:1.1em><div id=content><div class=container><a href=https://grussorusso.github.io/publications#mead-model-based-vertical-auto-scaling-for-data-stream-processing>back</a><h2>MEAD: Model-based Vertical Auto-Scaling for Data Stream Processing</h2><p>G. Russo Russo, V. Cardellini, G. Casale, F. Lo Presti</p><p class=paper-info>Proc. of IEEE/ACM CCGRID '21</p><p><a style=color:red href=http://www.ce.uniroma2.it/publications/ccgrid2021.pdf>[pdf]</i></a>
<a href=https://doi.org/10.1109/CCGrid51090.2021.00041>[doi]</i></i></a></p><p>The unpredictable variability of Data Stream Processing (DSP) application workloads calls for advanced mechanisms and policies for elastically scaling the processing capacity
of DSP operators. Whilst many different approaches have been
used to devise policies, most of the solutions have focused on data
arrival rate and operator resource utilization as key metrics for
auto-scaling. We here show that, under burstiness in the data
flows, overly simple characterizations of the input stream can
yet lead to very inaccurate performance estimations that affect
such policies, resulting in sub-optimal resource allocation.
We then present MEAD, a vertical auto-scaling solution
that relies on online state-based representation of burstiness
to drive resource allocation. We use in particular Markovian
Arrival Processes (MAPs), which are composable with analytical
queueing models, allowing us to efficiently predict performance
at run-time under burstiness. We integrate MEAD in Apache
Flink, and evaluate its benefits over simpler yet popular auto-scaling solutions, using both synthetic and real-world workloads.
Differently from existing approaches, MEAD satisfies response
time requirements under burstiness, while saving up to 50% CPU
resources with respect to a static allocation.</p></div></div><div id=footer class=mb-5><hr><div class="container text-center"><a href=https://github.com/grussorusso class="fab fa-github fa-1x" title=GitHub></a>
<a href="https://scholar.google.com/citations?user=rRiNfS0AAAAJ" class="ai ai-google-scholar fa-1x" title=Scholar></a>
<a href=https://dblp.org/pid/214/1442.html class="ai ai-dblp fa-1x" title=DBLP></a></div><div class="container text-center"><a href=https://grussorusso.github.io/ title><small></small></a></div></div><script src=https://code.jquery.com/jquery-3.5.1.slim.min.js integrity=sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js integrity=sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx crossorigin=anonymous></script></body></html>